"""
Mod√®le pr√©dictif de Chiffre d'Affaires
R√©gression multiple avec variables g√©od√©mographiques
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

class CAPredictor:
    """Mod√®le de pr√©diction du Chiffre d'Affaires"""
    
    def __init__(self):
        self.models = {}
        self.scaler = StandardScaler()
        self.label_encoders = {}
        self.feature_names = []
        self.best_model = None
        self.best_score = 0
        
    def prepare_features(self, df):
        """Pr√©pare les features pour la mod√©lisation"""
        
        # Copie des donn√©es
        data = df.copy()
        
        # Variables num√©riques
        numeric_features = [
            'surface_vente', 'effectif', 'population_zone_1km', 
            'densite_hab_km2', 'revenu_median_zone', 'age_moyen_zone',
            'concurrents_500m', 'concurrents_1km', 'parking_places',
            'distance_centre_ville', 'transport_score'
        ]
        
        # Encodage des variables cat√©gorielles
        categorical_features = ['enseigne', 'format', 'ville']
        
        for feature in categorical_features:
            if feature not in self.label_encoders:
                self.label_encoders[feature] = LabelEncoder()
                data[f'{feature}_encoded'] = self.label_encoders[feature].fit_transform(data[feature])
            else:
                data[f'{feature}_encoded'] = self.label_encoders[feature].transform(data[feature])
        
        # Variables d√©riv√©es (feature engineering)
        data['population_par_concurrent'] = data['population_zone_1km'] / (data['concurrents_500m'] + 1)\n        data['revenu_x_population'] = data['revenu_median_zone'] * data['population_zone_1km'] / 1000000\n        data['surface_par_employe'] = data['surface_vente'] / data['effectif']\n        data['densite_ajustee'] = data['densite_hab_km2'] / (data['distance_centre_ville'] + 1)\n        data['score_accessibilite'] = data['transport_score'] * data['parking_places'] / 100\n        data['zone_commerciale_num'] = data['zone_commerciale'].astype(int)\n        \n        # Variables temporelles\n        data['date_ouverture'] = pd.to_datetime(data['date_ouverture'])\n        data['anciennete_mois'] = (pd.Timestamp.now() - data['date_ouverture']).dt.days / 30.44\n        \n        # S√©lection des features finales\n        feature_columns = (numeric_features + \n                          [f'{f}_encoded' for f in categorical_features] +\n                          ['population_par_concurrent', 'revenu_x_population', \n                           'surface_par_employe', 'densite_ajustee', 'score_accessibilite',\n                           'zone_commerciale_num', 'anciennete_mois'])\n        \n        self.feature_names = feature_columns\n        return data[feature_columns]\n    \n    def train_models(self, df, target='ca_annuel'):\n        \"\"\"Entra√Æne plusieurs mod√®les et s√©lectionne le meilleur\"\"\"\n        \n        # Pr√©paration des donn√©es\n        X = self.prepare_features(df)\n        y = df[target]\n        \n        # Division train/test\n        X_train, X_test, y_train, y_test = train_test_split(\n            X, y, test_size=0.2, random_state=42\n        )\n        \n        # Normalisation\n        X_train_scaled = self.scaler.fit_transform(X_train)\n        X_test_scaled = self.scaler.transform(X_test)\n        \n        # D√©finition des mod√®les\n        models_config = {\n            'Linear_Regression': LinearRegression(),\n            'Ridge': Ridge(alpha=1.0),\n            'Lasso': Lasso(alpha=1.0),\n            'Random_Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n            'Gradient_Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n        }\n        \n        results = {}\n        \n        print(\"ü§ñ Entra√Ænement des mod√®les...\")\n        print(\"=\"*50)\n        \n        for name, model in models_config.items():\n            # Utiliser les donn√©es normalis√©es pour les mod√®les lin√©aires\n            if name in ['Linear_Regression', 'Ridge', 'Lasso']:\n                X_train_model = X_train_scaled\n                X_test_model = X_test_scaled\n            else:\n                X_train_model = X_train\n                X_test_model = X_test\n            \n            # Entra√Ænement\n            model.fit(X_train_model, y_train)\n            \n            # Pr√©dictions\n            y_pred_train = model.predict(X_train_model)\n            y_pred_test = model.predict(X_test_model)\n            \n            # M√©triques\n            train_r2 = r2_score(y_train, y_pred_train)\n            test_r2 = r2_score(y_test, y_pred_test)\n            test_mae = mean_absolute_error(y_test, y_pred_test)\n            test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n            \n            # Validation crois√©e\n            cv_scores = cross_val_score(model, X_train_model, y_train, cv=5, scoring='r2')\n            \n            results[name] = {\n                'model': model,\n                'train_r2': train_r2,\n                'test_r2': test_r2,\n                'cv_mean': cv_scores.mean(),\n                'cv_std': cv_scores.std(),\n                'mae': test_mae,\n                'rmse': test_rmse\n            }\n            \n            print(f\"{name}:\")\n            print(f\"  R¬≤ train: {train_r2:.3f}\")\n            print(f\"  R¬≤ test:  {test_r2:.3f}\")\n            print(f\"  CV R¬≤:    {cv_scores.mean():.3f} (¬±{cv_scores.std():.3f})\")\n            print(f\"  MAE:      {test_mae:,.0f}‚Ç¨\")\n            print(f\"  RMSE:     {test_rmse:,.0f}‚Ç¨\")\n            print()\n        \n        # S√©lection du meilleur mod√®le\n        best_model_name = max(results.keys(), key=lambda k: results[k]['cv_mean'])\n        self.best_model = results[best_model_name]['model']\n        self.best_score = results[best_model_name]['cv_mean']\n        \n        print(f\"üèÜ Meilleur mod√®le: {best_model_name} (R¬≤ CV: {self.best_score:.3f})\")\n        \n        self.models = results\n        return results, X_test, y_test\n    \n    def analyze_feature_importance(self, df):\n        \"\"\"Analyse l'importance des variables\"\"\"\n        \n        if self.best_model is None:\n            print(\"‚ùå Aucun mod√®le entra√Æn√©\")\n            return\n        \n        # Importance des features (si disponible)\n        if hasattr(self.best_model, 'feature_importances_'):\n            importance = self.best_model.feature_importances_\n            \n            feature_importance = pd.DataFrame({\n                'feature': self.feature_names,\n                'importance': importance\n            }).sort_values('importance', ascending=False)\n            \n            print(\"üìä Importance des variables:\")\n            print(feature_importance.head(10))\n            \n            # Graphique\n            plt.figure(figsize=(10, 6))\n            sns.barplot(data=feature_importance.head(10), x='importance', y='feature')\n            plt.title('Top 10 - Importance des variables')\n            plt.xlabel('Importance')\n            plt.tight_layout()\n            plt.show()\n            \n            return feature_importance\n        \n        elif hasattr(self.best_model, 'coef_'):\n            # Coefficients pour mod√®les lin√©aires\n            coefficients = pd.DataFrame({\n                'feature': self.feature_names,\n                'coefficient': self.best_model.coef_\n            }).sort_values('coefficient', key=abs, ascending=False)\n            \n            print(\"üìä Coefficients du mod√®le:\")\n            print(coefficients.head(10))\n            \n            return coefficients\n    \n    def predict_new_site(self, site_data):\n        \"\"\"Pr√©dit le CA d'un nouveau site\"\"\"\n        \n        if self.best_model is None:\n            raise ValueError(\"Aucun mod√®le entra√Æn√©\")\n        \n        # Pr√©paration des features\n        features = self.prepare_features(pd.DataFrame([site_data]))\n        \n        # Normalisation si n√©cessaire\n        if type(self.best_model).__name__ in ['LinearRegression', 'Ridge', 'Lasso']:\n            features_scaled = self.scaler.transform(features)\n            prediction = self.best_model.predict(features_scaled)[0]\n        else:\n            prediction = self.best_model.predict(features)[0]\n        \n        return prediction\n    \n    def save_model(self, filepath='../models/ca_predictor.joblib'):\n        \"\"\"Sauvegarde le mod√®le\"\"\"\n        \n        model_data = {\n            'best_model': self.best_model,\n            'scaler': self.scaler,\n            'label_encoders': self.label_encoders,\n            'feature_names': self.feature_names,\n            'best_score': self.best_score\n        }\n        \n        joblib.dump(model_data, filepath)\n        print(f\"‚úÖ Mod√®le sauvegard√©: {filepath}\")\n    \n    def load_model(self, filepath='../models/ca_predictor.joblib'):\n        \"\"\"Charge un mod√®le sauvegard√©\"\"\"\n        \n        model_data = joblib.load(filepath)\n        \n        self.best_model = model_data['best_model']\n        self.scaler = model_data['scaler']\n        self.label_encoders = model_data['label_encoders']\n        self.feature_names = model_data['feature_names']\n        self.best_score = model_data['best_score']\n        \n        print(f\"‚úÖ Mod√®le charg√©: {filepath}\")\n\n\ndef demo_prediction():\n    \"\"\"D√©monstration du mod√®le\"\"\"\n    \n    print(\"üöÄ D√âMONSTRATION - Mod√®le pr√©dictif CA\")\n    print(\"=\"*50)\n    \n    # Chargement des donn√©es\n    df = pd.read_csv('../data/magasins_performance.csv')\n    \n    # Initialisation et entra√Ænement\n    predictor = CAPredictor()\n    results, X_test, y_test = predictor.train_models(df)\n    \n    # Analyse des features\n    predictor.analyze_feature_importance(df)\n    \n    # Sauvegarde\n    predictor.save_model()\n    \n    # Exemple de pr√©diction pour un nouveau site\n    print(\"\\nüéØ Exemple de pr√©diction:\")\n    nouveau_site = {\n        'enseigne': 'SuperFrais',\n        'format': 'Supermarch√©',\n        'ville': 'Lyon',\n        'surface_vente': 1200,\n        'effectif': 25,\n        'population_zone_1km': 15000,\n        'densite_hab_km2': 3000,\n        'revenu_median_zone': 32000,\n        'age_moyen_zone': 38.5,\n        'concurrents_500m': 1,\n        'concurrents_1km': 3,\n        'parking_places': 150,\n        'distance_centre_ville': 2.5,\n        'transport_score': 7,\n        'zone_commerciale': True,\n        'date_ouverture': '2024-01-01'\n    }\n    \n    ca_predit = predictor.predict_new_site(nouveau_site)\n    print(f\"CA pr√©dit: {ca_predit:,.0f}‚Ç¨\")\n    \n    return predictor\n\n\nif __name__ == \"__main__\":\n    predictor = demo_prediction()